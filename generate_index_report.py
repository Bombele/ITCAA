import json
import faiss
from datetime import datetime
from src.itcaa_ai_offline import config

def generate_index_report():
    # Charger l'index FAISS
    index = faiss.read_index(str(config.PATHS.faiss_index))
    meta = json.loads(config.PATHS.meta_json.read_text(encoding="utf-8"))

    # D√©tecter les langues (simple heuristique par caract√®res Unicode)
    def detect_lang(text):
        if any("\u0600" <= ch <= "\u06FF" for ch in text): return "Arabe"
        if any("\u4E00" <= ch <= "\u9FFF" for ch in text): return "Chinois"
        if any("\u0400" <= ch <= "\u04FF" for ch in text): return "Russe"
        if any(ch in "√°√©√≠√≥√∫√±" for ch in text.lower()): return "Espagnol"
        if any(ch in "√†√¢√ß√©√®√™√´√Æ√Ø√¥√ª√π√º√ø" for ch in text.lower()): return "Fran√ßais"
        return "Anglais"

    languages = {detect_lang(m["text"]) for m in meta}

    # Construire le rapport Markdown
    report = f"""# üìä Rapport Index ITCAA

- **Date de derni√®re reconstruction** : {datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S")} UTC
- **Nombre total de passages index√©s** : {len(meta)}
- **Nombre total de vecteurs FAISS** : {index.ntotal}
- **Langues d√©tect√©es dans le corpus** : {", ".join(sorted(languages))}

## üîé D√©tails corpus
"""
    for i, m in enumerate(meta[:10], 1):  # afficher les 10 premiers passages
        report += f"- Passage {i}: {m['text'][:60]}...\n"

    # Sauvegarder le rapport
    (config.PATHS.index_dir / "index_report.md").write_text(report, encoding="utf-8")
    print("‚úÖ Rapport index_report.md g√©n√©r√©.")

if __name__ == "__main__":
    generate_index_report()